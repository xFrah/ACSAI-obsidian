---
aliases:
  - entropy
---
Entropy is a fundamental thermodynamic property that quantifies the **disorder or randomness** of a system. 
It also represents the **number of possible microscopic states (microstates)** that correspond to a given macroscopic state of a system.

Entropy can be understood through two main definitions:

### Macroscopic Definition

On a macroscopic scale, the **change in entropy ($dS$)** for a **reversible transformation** is defined by the ratio of the change of heat ($dQ$) to the absolute [[0. Internal energy - Temperature|temperature]] ($T$) at which the heat transfer occurs. 
$$\Large dS = \frac{dQ}{T}$$

For the change of entropy between an initial state $i$ and a final state $f$, it is calculated as the [integral](../../Calculus%20U2/7.%20Definite%20Integrals.md) of this ratio: 
$$\Large \Delta S = \int_i^f \frac{dQ}{T}$$

> [!note]
>  The unit for entropy is typically Joules per Kelvin ($\text{J/K}$).


### Microscopic Definition

On a microscopic scale, entropy is related to the **number of approximated microstates ($W$)** available to a system. This definition connects entropy to the probability of different configurations of particles within a given volume. $$\Large S_f - S_i = nR \ln \left( \frac{V_f}{V_i} \right) = K_B \ln(W) \text{2}$$ Where:

- $S_f$ is the final entropy.
- $S_i$ is the initial entropy.
- $n$ is the number of moles of the gas.
- $R$ is the universal gas constant.
- $V_f$ is the final volume.
- $V_i$ is the initial volume.
- $K_B$ is the Boltzmann constant.
- $W$ is the number of approximated microstates. 


> [!note]
> The number of possible positions for a molecule within a volume $V_f$ compared to its own volume $V_m$ is $V_f/V_m$. For multiple molecules, this becomes $(V_f/V_m)^N$ or similar expressions leading to the logarithmic relationship.
